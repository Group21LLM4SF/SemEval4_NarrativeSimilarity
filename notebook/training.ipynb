{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24b38f20",
   "metadata": {},
   "source": [
    "# Training Notebook - Narrative Similarity (SemEval4)\n",
    "\n",
    "This notebook implements the training of `AspectSupervisedEncoder` model for **narrative similarity** based on triplet learning with aspect attention. The model uses a pre-trained encoder (DistilBERT) with specialized projections to capture narrative similarity between texts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fa78e0",
   "metadata": {},
   "source": [
    "## 1. Path Setup\n",
    "\n",
    "The main directory is added to the system path to enable importing modules from the `src` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d44c4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50189458",
   "metadata": {},
   "source": [
    "## 2. Import Libraries\n",
    "\n",
    "All necessary dependencies are imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d736d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils.data import DataLoader\n",
    "from src.trainer import Trainer\n",
    "from src.datasets.dataset import AspectTripletDatasetTrain, AspectTripletDatasetDev, load_aspect_triplets, load_eval_triplets\n",
    "from src.trainer import Trainer\n",
    "from src.models.encoder import AspectSupervisedEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bc24de",
   "metadata": {},
   "source": [
    "## 3. Load Data\n",
    "\n",
    "The preprocessed data is loaded:\n",
    "- **Training data**: triplets (anchor, positive, negative) with augmentation based on narrative aspects\n",
    "- **Eval data**: triplets for model validation\n",
    "\n",
    "The files are in JSONL format and contain examples already processed for triplet learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab86340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 60)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = load_aspect_triplets(\"./data/processed/train_from_dev_w_aspect_aug_triplets.jsonl\")\n",
    "eval_data = load_eval_triplets(\"./data/processed/eval_from_dev_triplets.jsonl\")\n",
    "\n",
    "len(training_data), len(eval_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d074bfd",
   "metadata": {},
   "source": [
    "## 4. Create DataLoaders\n",
    "\n",
    "The datasets and DataLoaders for training are created:\n",
    "- **AspectTripletDatasetTrain**: dataset for training with triplets (anchor, positive, negative)\n",
    "- **AspectTripletDatasetDev**: dataset for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02bd3399",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AspectTripletDatasetTrain(training_data)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=12, shuffle=True)\n",
    "\n",
    "eval_dataset = AspectTripletDatasetDev(eval_data)\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=12, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14f9500",
   "metadata": {},
   "source": [
    "## 5. Model Configuration\n",
    "\n",
    "The **AspectSupervisedEncoder** is initialized with the following parameters:\n",
    "\n",
    "| Parameter | Value | Description |\n",
    "|-----------|-------|-------------|\n",
    "| `model_name` | distilbert-base-uncased | Pre-trained transformer model as base encoder |\n",
    "| `projection_dim` | 256 | Dimension of the projected embedding space |\n",
    "| `aspect_dim` | 128 | Dimension of aspect representations |\n",
    "| `num_heads` | 4 | Number of attention heads for multi-head attention |\n",
    "| `dropout` | 0.3 | Dropout probability for regularization |\n",
    "| `freeze_encoder` | True | Freeze pre-trained encoder weights |\n",
    "| `use_lora` | False | LoRA (Low-Rank Adaptation) disabled |\n",
    "\n",
    "**Note**: LoRA parameters (`lora_r=8`, `lora_alpha=16`) are configured but not active when `use_lora=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdddfaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = AspectSupervisedEncoder(\n",
    "    model_name=\"distilbert-base-uncased\", # You can change to other models\n",
    "    projection_dim=256, \n",
    "    aspect_dim=128,\n",
    "    num_heads=4,\n",
    "    dropout=0.3,\n",
    "    freeze_encoder=True,\n",
    "    use_lora=False,\n",
    "    lora_r=8, # DO NOT CHANGE THIS VALUE\n",
    "    lora_alpha=16,# DO NOT CHANGE THIS VALUE\n",
    "    lora_dropout=0.1, \n",
    "    target_modules=[\"q_lin\", \"v_lin\"]  # For DistilBERT. See above for other models\n",
    ")\n",
    "\n",
    "# Count params\n",
    "total = sum(p.numel() for p in model.parameters())\n",
    "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Parameters: {trainable:,} trainable / {total:,} total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a343d69",
   "metadata": {},
   "source": [
    "## 6. Model Training\n",
    "\n",
    "Training is configured and started.\n",
    "It automatically uses the GPU if available (CUDA), otherwise the CPU is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c132f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "LR = 1e-4\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    device=DEVICE,\n",
    "    lr=LR,\n",
    "    weight_decay=0.01,\n",
    "    triplet_margin=0.5,\n",
    "    cross_margin=0.3,\n",
    "    gamma=0.3, # related to aspect loss\n",
    "    beta=1.0 # related to cross loss\n",
    ")\n",
    "\n",
    "# Train\n",
    "trainer.fit(train_dataloader, eval_dataloader, epochs=EPOCHS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
